# -*- coding: utf-8 -*-
"""Project_Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LSYMjSay0ghKAhN2Ov22nM06728F0fNq

<h1> <b>Sistem Rekomendasi Film<b> <h1>

# Import Library

Mengimpor library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import zipfile
from sklearn.feature_extraction.text import TfidfVectorizer
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""# Data Loading

Mengunduh data dari https://www.kaggle.com/datasets/bandikarthik/movie-recommendation-system Dataset kemudian diunggah ke *google drive*, lalu untuk memuat data di Google Collab menggunakan Mounted drive.

Dataset ini terdiri dari beberapa dataset berikut:

* links : daftar link film.
* movies : daftar film.
* ratings : daftar penilaian yang diberikan pengguna terhadap film.
* tags : daftar kata kunci dari film tersebut

"""

# Mounted drive untuk menyambungkan file drive dengan sheet colab
from google.colab import drive
drive.mount('/content/drive')

# Mengekstrak dataset
zip_ref = zipfile.ZipFile("/content/drive/MyDrive/Colab_Notebooks/Movie_Recomendation.zip", 'r')
zip_ref.extractall("/tmp")
zip_ref.close()

# Membuat dataframe 
links = pd.read_csv('/tmp/links.csv')
movies = pd.read_csv('/tmp/movies.csv')
ratings = pd.read_csv('/tmp/ratings.csv')
tags = pd.read_csv('/tmp/tags.csv')

"""# Explanatory Data Analysis

Melakukan beberapa tahapan sebagai berikut : 

1.   Deskripsi dataset
2.   Deskripsi variabel pada dataset

##Deskripsi Dataset **links**
"""

links.info()

"""Dataset terdiri dari:

*   34208 data dalam links
*   2 buah kolom bertipe int64 yaitu movieId dan imdbId 
*   1 buah kolom bertipe float64 yaitu tmdbId

## Deskripsi Dataset **movies**
"""

movies.info()

"""Dataset terdiri dari:

*   34208 data dalam links
*   1 buah kolom bertipe int64 yaitu movieId
*   2 buah kolom bertipe object yaitu title dan genres 


"""

print('Jumlah data movies : ', len(movies.movieId.unique()))
print('Jumlah judul film: ', len(movies.title.unique()))
print('Jumlah genre film: ', len(movies.genres.unique()))

"""## Deskripsi dataset **ratings**"""

ratings.info()

"""Dataset terdiri dari:

*   22884377 data dalam links
*   3 buah kolom bertipe int64 yaitu userId, movieId dan timestamp
*   1 buah kolom bertipe float64 yaitu rating

Karena data terlalu banyak, maka data yang akan digunakan hanya 10000 data saja
"""

# Memuat dataset rating sebanyak 10000 record data
ratings = ratings.iloc[:10000,:]

# Cek ukuran dataset 
ratings.shape

print('Jumlah data ratings dari user : ', len(ratings.userId.unique()))
print('Jumlah data ratings dari movie : ', len(ratings.movieId.unique()))

ratings.describe()

"""Dapat kita lihat dari nilai max dan min bahwa nilai rating terbesar yaitu 5, dan nilai rating terkecil yaitu 0.5

## Deskripsi dataset **tags**
"""

tags.info()

"""Dataset terdiri dari:

*   586994 data dalam links
*   3 buah kolom bertipe int64 yaitu userId, movieId dan timestamp
*   1 buah kolom bertipe object yaitu tag

Karena data terlalu banyak, maka data yang akan digunakan hanya 10000 data saja
"""

# Memuat dataset rating sebanyak 10000 record data
tags = tags.iloc[:10000,:]

# Cek ukuran dataset 
tags.shape

print('Jumlah tag movie: ', len(tags.tag.unique()))

"""# Content Based Filtering

## Data Preprocessing

### Menggabungkan variable **movieId** di dataset movies
"""

import numpy as np
 
# Menggabungkan seluruh movieId pada kategori movie
movie_all = np.concatenate((
    links.movieId.unique(),
    movies.movieId.unique(),
    ratings.movieId.unique(),
    tags.movieId.unique(),
))
 
# Mengurutkan data dan mengambil record data yang unik atau tidak duplikat
movie_all = np.sort(np.unique(movie_all))
 
print('Jumlah seluruh data movie berdasarkan movieID: ', len(movie_all))

"""### Menggabungkan variabel **userId** di dataset movies"""

# Menggabungkan seluruh userId
user_all = np.concatenate((
    ratings.userId.unique(),
    tags.userId.unique(),
   
))
 
# Mengurutkan data dan mengambil record data yang unik atau tidak duplikat
user_all = np.sort(np.unique(user_all)) 
 
print('Jumlah seluruh user: ', len(user_all))

"""### Membuat dataframe all_movie_rate"""

# Mendefinisikan dataframe all_movie_rate yang berisi rating
all_movie_rate = ratings
all_movie_rate

# Menggabungkan variabel userId, movieId, title, dan genres keseluruhan ke dalam dataframe all_movie_rate
all_movie_name = pd.merge(all_movie_rate, movies[['movieId','title','genres']], on='movieId', how='left')
all_movie_name

# Menggabungkan variabel movieId, dan tag ke dalam dataframe all_movie_rate
all_movie = pd.merge(all_movie_name, tags[['movieId','tag']], on='movieId', how='left')
all_movie

"""## Data Preparation

### Menangani missing value
"""

# cek missing value
all_movie.isnull().sum()

"""Terdapat  3675 missing value terhadap fitur tag. Untuk menghindari bias, missing value tidak diisi dengan modus. Maka missing value akan di hapus menggunakan fungsi dropna"""

all_movie_clean = all_movie.dropna()
all_movie_clean

# cek ulang missing value
all_movie_clean.isnull().sum()

"""Missing value sudah tidak ada

### Mengurutkan Data

Mengurutkan data secara ascending
"""

# Mengurutkan film berdasarkan movieId ke dalam variabel fix_movie
fix_movie = all_movie_clean.sort_values('movieId', ascending=True)
fix_movie

# Mengecek jumlah record data fix movie
len(fix_movie.movieId.unique())

# Membuat variabel preparation yang berisi dataframe fix_movie kemudian mengurutkan berdasarkan movieId
preparation = fix_movie
preparation.sort_values('movieId', ascending=True)

"""### Menangani data duplikat

Menghapus data yang duplikat dengan fungsi drop_duplicates(). Dalam hal ini, membuang data duplikat pada kolom ‘movieId’.
"""

# Menghapus data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movieId')
preparation

"""### Konversi data menjadi list

Melakukan konversi data series menjadi list.
"""

# Mengkonversi data series ‘movieId’ menjadi dalam bentuk list
movie_id = preparation['movieId'].tolist()
 
# Mengkonversi data series ‘title’ menjadi dalam bentuk list
movie_name = preparation['title'].tolist()
 
# Mengkonversi data series ‘genres’ menjadi dalam bentuk list
movie_genre = preparation['genres'].tolist()
 
print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

"""### Membuat Dictionary
Membuat dictionary untuk menentukan pasangan key-value pada data movie_id, movie_name, dan movie_genre yang telah disiapkan sebelumnya
"""

# Membuat dictionary untuk data ‘movie_id’, ‘movie_name’, dan ‘movie_genre’
movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""## Modelling

### TF-IDF Vectorizer
Digunakan untuk menemukan representasi fitur penting dari setiap kategori film.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tfid = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data genre
tfid.fit(movie_new['genre']) 
 
# Mapping array dari fitur index integer ke fitur nama
tfid.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tfid.fit_transform(movie_new['genre']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Nilai 1442 merupakan ukuran data dan 21 merupakan matrik kategori film"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis film
# Baris diisi dengan nama film

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tfid.get_feature_names(),
    index=movie_new.movie_name
).sample(10, axis=1,replace=True).sample(10, axis=0,replace=True)

"""### Cosine Similarity 
Menghitung derajat kesamaan (similarity degree) antar film dengan teknik cosine similarity. Dengan menggunakan fungsi cosine_similarity dari library sklearn. 
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama film
cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_new['movie_name'], columns=movie_new['movie_name'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap film 
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## Evaluasi

### Mendapatkan Rekomendasi
Membuat fungsi movie_recommendations dengan parameter:

* movie_name : judul dari movie tersebut (index kemiripan dataframe).
* similarity_data : dataframe similarity data
* items : nama dan fitur yang digunakan untuk mendefinisikan kemiripanh ‘movie_name’ dan ‘genre’.
* k : jumlah rekomendasi yang ingin diberikan.
"""

def movie_recommendations(movie_name, similarity_data=cosine_sim_df, items=movie_new[['movie_name', 'genre']], k=5):
   
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,movie_name].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop movie_name agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(movie_name, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

movie_new[movie_new.movie_name.eq('Jumanji (1995)')]

# Hasil rekomendasi film yang mirip dengan 'Jumanji (1995)' 
movie_recommendations('Jumanji (1995)')

"""# Collaborative Filtering

## Data Understanding
Supaya tidak tertukar dengan fitur ‘rating’ pada data, kita ubah nama variabel rating menjadi df_rating
"""

# Membaca dataset
df_rating = ratings
df_rating

"""Data ratings terdiri dari 10000 baris dan 4 kolom

## Data Preparation

### Encode fitur userId dan movieId
Melakukan persiapan data untuk menjadikan (encode) fitur ‘userId’ dan ‘movieID’ ke dalam indeks integer
"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = df_rating['userId'].unique().tolist()
print('list userId: ', user_ids)
 
# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('hasil encode userId : ', user_to_user_encoded)
 
# Melakukan proses encoding angka ke ke userId
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('hasil encode angka ke userId: ', user_encoded_to_user)

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df_rating['movieId'].unique().tolist()
 
# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
 
# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""### Memetakan userId dan movieId
Petakan userId dan movieId ke dataframe yang berkaitan.
"""

# Mapping userId ke dataframe genres
df_rating['genres'] = df_rating['userId'].map(user_to_user_encoded)
 
# Mapping movieD ke dataframe movies
df_rating['movies'] = df_rating['movieId'].map(movie_to_movie_encoded)

"""### Cek data dan ubah nilai rating
Terakhir, cek beberapa hal dalam data seperti jumlah user, jumlah movie, dan mengubah nilai rating menjadi float, cek nilai minimum dan maximum
"""

num_users = len(user_to_user_encoded)
print(num_users)
 
num_movie = len(movie_encoded_to_movie)
print(num_movie)
 
df_rating['ratings'] = df_rating['rating'].values.astype(np.float32)
 
min_rating = min(df_rating['rating'])
 
max_rating = max(df_rating['rating'])
 
print('Jumlah User: {}, Jumlah movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""### Membagi data untuk latih dan validasi

membagi data latih dan validasi dengan komposisi 80:20
"""

# Mengacak dataset
df = df_rating.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data genres dan movies menjadi satu value
x = df[['genres', 'movies']].values
 
# Membuat variabel y untuk membuat ratings dari hasil 
y = df['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""## Modelling

### Proses Latih

Membuat class RecommenderNet dengan keras Model class. Model ini menggunakan metrics evaluation berupa :
* Binary Crossentropy untuk menghitung loss function
* Adam (Adaptive Moment Estimation) sebagai optimizer
* root mean squared error (RMSE) sebagai metrics evaluation
"""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movies
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movies bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

# Inisialisasi model
model = RecommenderNet(num_users, num_movie, 25) 

# Model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
 
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 50,
    validation_data = (x_val, y_val)
)

"""## Evaluasi

Evaluasi dilakukan dengan menggunakan matriks Root Mean Squared Error (RMSE).
"""

# Visualisasi RMSE
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Hasilnya nilai error akhir sebesar sekitar 0.15 dan error pada data validasi sebesar 0.24.

### Mendapatkan Rekomendasi

Untuk mendapatkan rekomendasi film, pertama kita ambil sampel user secara acak dan definisikan variabel movie_not_watched yang merupakan daftar film yang belum pernah ditonton oleh pengguna
"""

movie_df = movie_new
df = pd.read_csv('/tmp/ratings.csv')
df = df.iloc[:10000,:]

user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]

movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id'] 
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys())))
 
movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched))

# Memperoleh rekomendasi film menggunakan fungsi model.predict() dari library Keras
ratings = model.predict(user_movie_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)
 
top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
 
movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)
 
print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)
 
recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)